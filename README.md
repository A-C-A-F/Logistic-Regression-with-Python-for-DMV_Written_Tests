# Logistic-Regression-with-Python-for-DMV_Written_Tests
Logistic Regression with NumPy and Python


Unlike in the case of linear regression, where we're trying to predict a real and continuous valued output, logistic regression is a classification algorithm and it tries to predict a discrete set of class labels for the given input.

 __Data Source:__ *https://www.kaggle.com/datasets/arielfelices/acaf-dataset-collection?select=DMV_Written_Tests.csv*

Our dataset is __DMV_Written_Tests.csv__. This dataset is comprised of written test scores. We will be trying to predict if a person with those test scores passed or failed. This dataset contains scores for two written test at the DMV. It also contains the result.

### Below are the key objectives of this project:
1.	Implement the gradient descent algorithm from scratch.
2.	Perform logistic regression with NumPy and Python.
3.	Create data visualizations with Matplotlib and Seaborn


### Below is the summary of the tasks performed in this project:
- __Task 1:__ Load the Data and Import Libraries
- __Task 2:__ Visualize the Data
- __Task 3:__ Define the Logistic Sigmoid Function 𝜎(𝑧)
- __Task 4:__ Compute the Cost Function 𝐽(𝜃) and Gradient
- __Task 5:__ Cost and Gradient at Initialization
- __Task 6:__ Implement Gradient Descent from scratch
- __Task 7:__ Plotting the Convergence of  𝐽(𝜃)
- __Task 8:__ Plotting the decision boundary
- __Task 9:__ Predictions using the optimized 𝜃 values
